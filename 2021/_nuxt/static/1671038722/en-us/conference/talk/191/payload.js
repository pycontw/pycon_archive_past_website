__NUXT_JSONP__("/en-us/conference/talk/191", (function(a,b){a.id=191;a.begin_time="2021-10-02T02:05:00Z";a.end_time="2021-10-02T02:35:00Z";a.is_remote=false;a.location="5-r1";a.youtube_id="yxczI4BpT8Y";a.title="自問自答:命名實體識別應用於精準醫療服務-以智能理賠為例";a.category="NLP";a.language="ZHZH";a.python_level="INTERMEDIATE";a.recording_policy=true;a.abstract="如何效率地從龐大的非結構化文字資料，萃取重要的結構化資訊是大數據分析的基礎。本次演講以結合金融業務與精準醫療為出發點，藉由智能理賠(醫囑分析)作為案例，探討如何透過自然語言處理技術，將瑣碎且重複性極高的作業流程逐步化繁為簡。\r\n\r\n就技術而言，此乃自然語言處理領域中的命名實體識別任務。在現今預訓練與微調兩階段模式盛行之下，以Transformers為基調的模型在此任務已達一定水準。但是，當資料具有多含義實體(同一實體具有兩個以上含義，e.g. 急診日期通常也隱含了入院日期的含義)時，模型僅僅具備七成至八成的辨識水準，而多含義實體在醫囑資料或醫療文獻尤為常見，因此，我提出一種深度學習應用框架-自問自答，同時處理單含義與多含義實體。\r\n\r\n以一篇醫囑來說，模型自問多個問題(e.g. 請找出入院日期。)，根據這些問題，回答相應的實體答案。而多含義實體的各個意義，可被不同的獨立問題所切分開來，因而巧妙解決多含義實體問題。\r\n\r\n演講過程中，我會以知名的Python套件(Transformers)與Pytorch為實作核心，輔以介紹，透過Transformers套件可快速套用許多預訓練模型，並實現在自身資料集裡。最後，搭配實際展示引導聽眾了解整個問題與解法的脈絡。";a.detailed_description="### 使用的第三方工具：\r\n- [transformers] 為自然語言處理領域中熱門的Python套件，提供許多方便好用的API，且提供完整[tutorial]與免費[pretrained model]資源。\r\n- [seqeval] 為處理序列框架的常見評估工具。\r\n\r\n[transformers]: https:\u002F\u002Fgithub.com\u002Fhuggingface\u002Ftransformers\r\n[tutorial]: https:\u002F\u002Fhuggingface.co\u002Ftransformers\u002F\r\n[pretrained model]: https:\u002F\u002Fhuggingface.co\u002Fmodels\r\n[seqeval]: https:\u002F\u002Fgithub.com\u002Fchakki-works\u002Fseqeval";a.slide_link=b;a.slido_embed_link="https:\u002F\u002Fapp.sli.do\u002Fevent\u002Fwlkf9ipy";a.hackmd_embed_link="https:\u002F\u002Fhackmd.io\u002F@pycontw\u002FHkTtQkYfF\u002Fedit";a.speakers=[{thumbnail_url:"https:\u002F\u002Ftw.pycon.org\u002Ftemp\u002Fmedia\u002Fcache\u002Faa\u002Ffd\u002Faafd829a974560007af1946770a4140d.jpg",name:"江侑倫",github_profile_url:"https:\u002F\u002Fgithub.com\u002Fallenyummy",twitter_profile_url:"https:\u002F\u002Ftwitter.com\u002F_YLChiang",facebook_profile_url:b,bio:"NLP Engineer at CTBC bank"}];a.event_type="talk";return {data:[{speechData:a}],fetch:{},mutations:[["setSpeechData",a]]}}({},"")));