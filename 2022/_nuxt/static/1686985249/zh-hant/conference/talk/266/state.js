window.__NUXT__=(function(a,b){return {staticAssetsBase:"\u002F2022\u002F_nuxt\u002Fstatic\u002F1686985249",layout:"default",error:a,state:{sponsorsData:[],jobsData:[],schedulesData:[],keynotesData:[],youtubeInfo:[],speechesData:[],speechData:{id:266,begin_time:"2022-09-03T02:45:00Z",end_time:"2022-09-03T03:15:00Z",is_remote:false,location:"5-r1",youtube_id:"",title:"Hacking and Securing Machine Learning Systems and Environments",category:"SEC",language:"ENEN",python_level:"EXPERIENCED",recording_policy:b,abstract:"It is not an easy task to design and build machine learning systems. ML practitioners deploy ML models by converting some of their Jupyter Notebook Python code into production-ready application code. Once these ML systems have been set up, they need to be secured properly to manage vulnerabilities and exploits. \r\n\r\nThere are different ways to attack ML systems and most data science teams are not equipped with the skills required to secure these systems. We will discuss in detail several strategies and solutions on how to secure these systems.\r\n\r\nIn this session, we will review several attacks customized to take advantage of vulnerabilities present in Python libraries such as Joblib, urllib, and PyYAML. In addition to these, we'll check possible attacks on ML inference endpoints built using frameworks such as Flask, Pyramid, or Django. Finally, we will talk about several examples on how ML environments using ML frameworks (such as TensorFlow and PyTorch) can be attacked and compromised.",detailed_description:"Designing and building machine learning systems require a lot of skill, time, and experience. Data scientists, developers, and ML engineers work together in building ML systems and pipelines that automate different stages of the machine learning process. Once the ML systems have been set up, these systems need to be secured properly to prevent these systems from being hacked and compromised.\r\n\r\nML systems are generally built using **Python** and some attacks have been customized to take advantage of vulnerabilities present in certain Python libraries such as **Joblib**, **urllib**, and **PyYAML**. Other attacks may take advantage of vulnerabilities present in the custom code of ML engineers as well. In addition to these, we'll take a look at certain attack vectors available for certain cloud SDKs (e.g., **SageMaker Python SDK**) available in Python. There are different ways to attack machine learning systems and most data science teams are not equipped with the skills required to secure the systems they built. In this talk, we will discuss in detail the **cybersecurity attack chain** and how this affects a company's strategy when setting up different layers of security. We will discuss the different ways ML systems can be attacked and compromised and along the way, we will share the relevant strategies to mitigate these attacks. This includes attacks performed in deployed custom APIs (ML inference endpoints) built using known Python frameworks (e.g., **Flask**, **Pyramid**, **Django**) along with serverless applications and architectures written in Python (e.g., **Chalice**). \r\n\r\nFinally, we will show how to review and assess new discovered vulnerabilities in Python libraries and packages. We will share some tips and techniques on how to check if any of your ML systems and environments are vulnerable to certain types of attacks. We'll do these by sharing some examples using ML frameworks such as **PyTorch** and **TensorFlow**.",slide_link:"https:\u002F\u002Fspeakerdeck.com\u002Farvslat\u002Fpycon-apac-2022-hacking-and-securing-machine-learning-environments-and-systems",slido_embed_link:"https:\u002F\u002Fapp.sli.do\u002Fevent\u002F8YJfRpFFZpeVsK6NVgX24o",hackmd_embed_link:"https:\u002F\u002Fhackmd.io\u002F@pycontw\u002FHyvj8pmJs",speakers:[{thumbnail_url:"https:\u002F\u002Ftw.pycon.org\u002Ftemp\u002Fmedia\u002Fcache\u002Fdc\u002F03\u002Fdc0301edf78755efd0cf515d47ef6595.jpg",name:"Joshua Arvin Lat",github_profile_url:"https:\u002F\u002Fgithub.com\u002Fjoshualat",twitter_profile_url:"https:\u002F\u002Ftwitter.com\u002Fmrjoshualat",facebook_profile_url:"https:\u002F\u002Fwww.facebook.com\u002Fjosh.lat\u002F",bio:"Joshua Arvin Lat is the Chief Technology Officer (CTO) of NuWorks Interactive Labs, Inc. He previously served as the CTO of 3 Australian-owned companies and also served as the Director for Software Development and Engineering for multiple e-commerce startups in the past which allowed him to be more effective as a leader. Years ago, he and his team won 1st place in a global cybersecurity competition with their published research paper. He is also an AWS Machine Learning Hero and he has been sharing his knowledge in several international conferences to discuss practical strategies on machine learning, engineering, security, and management. He is the author of the book \"Machine Learning with Amazon SageMaker Cookbook\""}],event_type:"talk"},relatedData:[],i18n:{routeParams:{}}},serverRendered:b,routePath:"\u002Fzh-hant\u002Fconference\u002Ftalk\u002F266",config:{gtm:{id:void 0},_app:{basePath:"\u002F2022\u002F",assetsPath:"\u002F2022\u002F_nuxt\u002F",cdnURL:a}}}}(null,true));